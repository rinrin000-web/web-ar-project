<!DOCTYPE html>
<html>
  <head>
    <title>Basic WebAR Example with Image Tracking</title>
    <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ar-js-org/ar.js@3.3.2/aframe/build/aframe-ar-nft.min.js"></script>
  </head>
  <body style="margin : 0px; overflow: hidden;">
    <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
    <!-- <div class="arjs-loader">
      <div>Loading, please wait...</div>
    </div> -->
  
    <!-- a-frame scene -->
    <a-scene
      vr-mode-ui="enabled: false;"
      renderer="logarithmicDepthBuffer: true;"
      embedded
      arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"
    >
      <!-- a-nft is the anchor that defines an Image Tracking entity -->
      <!-- on 'url' use the path to the Image Descriptors created before. -->
      <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
      <a-nft
        type="nft"
        url="https://raw.githubusercontent.com/rinrin000-web/WEB-AR/main/uchiha2.jpg"
        smooth="true"
        smoothCount="10"
        smoothTolerance=".01"
        smoothThreshold="5"
      >
        <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
        
        <a-box position="0 0.5 0" material="color: green;"></a-box>
        
      </a-nft>
      <!-- static camera that moves according to the device movemenents -->
      <a-entity camera></a-entity>
    </a-scene>
  </body>
</html>
